import { Scanner } from './scanner';
import { Tags, Token, RuntimeTag, RuntimeComment, RuntimeMustache, LexerTagDefinitionContract } from './types';
export declare class Tokenizer {
    private template;
    private tagsDef;
    private options;
    tokens: Token[];
    tagStatement: null | {
        scanner: Scanner;
        tag: RuntimeTag;
    };
    mustacheStatement: null | {
        scanner: Scanner;
        mustache: RuntimeMustache | RuntimeComment;
    };
    private line;
    private isLastLineATag;
    private dropNewLine;
    private openedTags;
    constructor(template: string, tagsDef: Tags, options: {
        filename: string;
        onLine?: (line: string) => string;
        claimTag?: (name: string) => LexerTagDefinitionContract | null;
    });
    private getRawNode;
    private getNewLineNode;
    private getTagNode;
    private consumeTag;
    private handleTagOpening;
    private feedCharsToCurrentTag;
    private getMustacheType;
    private getMustacheNode;
    private getCommentNode;
    private handleMustacheOpening;
    private feedCharsToCurrentMustache;
    private isClosingTag;
    private consumeNode;
    private pushNewLine;
    private processText;
    private checkForErrors;
    parse(): void;
}
